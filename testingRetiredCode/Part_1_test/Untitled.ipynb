{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import islice\n",
    "from numba import jit\n",
    "\n",
    "#cache dictionary\n",
    "product_cache = {}\n",
    "\n",
    "#version 2\n",
    "#Added functions to improve computation time \n",
    "#1\n",
    "\n",
    "def CalcMeanLib(lst):\n",
    "    arr = np.array(lst)\n",
    "    return np.mean(arr)\n",
    "\n",
    "def CalcMean(lst):\n",
    "    Sum = 0\n",
    "    for i in range(0,len(lst)):\n",
    "        Sum = Sum + lst[i]\n",
    "    Mean = Sum/len(lst)    \n",
    "    return(Mean)\n",
    "\n",
    "#2\n",
    "def CalcSD(lst, Mean):\n",
    "    SD = 0\n",
    "    for i in range(0,len(lst)):\n",
    "        SD = SD + (lst[i]-Mean)*(lst[i]-Mean)\n",
    "    SD = math.sqrt(SD/len(lst))        \n",
    "    return(SD)    \n",
    "\n",
    "\n",
    "def CalcSDLib(lst):\n",
    "    arr = np.array(lst)\n",
    "    return np.std(arr)\n",
    "\n",
    "\n",
    "#3\n",
    "def CalcCrossCorr(f,g,fmean,gmean):\n",
    "    Sum=0\n",
    "    for i in range(0,len(f)):\n",
    "        Sum = Sum + (f[i]-fmean)*(g[i]-gmean)\n",
    "    CrossCorr = Sum/len(f)\n",
    "    return(CrossCorr)\n",
    "\n",
    "\n",
    "def CalcCrossCorrLib(f, g):\n",
    "    f = np.array(f)\n",
    "    g = np.array(g)\n",
    "    return np.corrcoef(f, g)[0, 1]\n",
    "\n",
    "\n",
    "#4    \n",
    "def CalcNormalisedCrossCorr(f,g,fmean,gmean,fsd,gsd):\n",
    "\n",
    "    Sum = 0\n",
    "    for i in range(0,len(f)):\n",
    "        Sum = Sum + (f[i]-fmean)*(g[i]-gmean)\n",
    "    NormCrossCorr = Sum/(len(f)*fsd*gsd)\n",
    "    return(NormCrossCorr)\n",
    "    \n",
    "def CalcNormalisedCrossCorrLib(f,g):\n",
    "    crr = CalcCrossCorrLib(f, g)\n",
    "    return crr / len(crr)\n",
    "\n",
    "\n",
    "def calculate_energy( p, g_slice ): # - memoise \n",
    "    \"\"\"\n",
    "    Normalisation for 1D slice of N size array of same length of pattern passed.\n",
    "    norm= sqrt( sum(p[i]^2) * sum(g[m]^2) )\n",
    " \n",
    "    Inputs:\n",
    "    ----------------\n",
    "        p   Pattern must be non empty and sum-square of its elements precalculated and passed\n",
    "\n",
    "        t   Template with similar dimensionality to pattern\n",
    "\n",
    "        offset  Offset position in the template/search array\n",
    "\n",
    "        len_p   offset for end-of-slice index for the slice of template\n",
    "        \n",
    "    Output:\n",
    "    ----------------\n",
    "        norm  Scalar float of variance for a given slice of the template/search and pattern\n",
    "     \"\"\"\n",
    "\n",
    "    return np.sqrt( np.sum( np.square*( p ) ) * np.sum( np.square( g ) ) )\n",
    "\n",
    "    #g_slice = t[ offset : offset + len_p ] \n",
    "    # norm = np.sqrt( p * ( g_slice**2).sum() ) \n",
    "    # if norm == 0 :\n",
    "    #     print (\"p=\", p, \"template=\", g_slice, \"offset = \", offset, \"\\n\")\n",
    "    # return norm\n",
    "\n",
    "#@jit(nopython=True)\n",
    "def calculate_score( pattern, template, offset):\n",
    "    \"\"\"\n",
    "    Correlation for 1D slice of N size template/search array with pattern at given offset. Sum(f[i]*g[i+m])\n",
    " \n",
    "    Inputs:\n",
    "    ----------------\n",
    "        pattern   Pattern must be non empty and sum-square of its elements precalculated and passed\n",
    "\n",
    "        template   Template with similar dimensionality to pattern\n",
    "\n",
    "        offset  Offset position in the template/search array\n",
    "        \n",
    "    Output:\n",
    "    ----------------\n",
    "        score  Scalar float of correlation score between pattern and template slice\n",
    "     \"\"\"    \n",
    "    #not faster \n",
    "    # slice_template = template[ offset : offset + len(pattern) ]\n",
    "    # score  = np.dot( pattern, slice_template ) \n",
    "    #Mutltiply and add each element of the pattern and template\n",
    "\n",
    "    pattern = np.array(pattern)\n",
    "    template = np.array(template)\n",
    "    \n",
    "    p = pattern.shape[0]\n",
    "    t = pattern.shape[0]\n",
    "\n",
    "    t_slice = template[offset : np.min(t, offset + p)]\n",
    "    p_slice = pattern[:t_slice.shape[0]]\n",
    "\n",
    "    return np.dot(t_slice, p_slice)\n",
    "\n",
    "    #score = 0 \n",
    "    #for i in range(len( pattern )):\n",
    "    #    o = i + offset\n",
    "    #    #try:\n",
    "    #    if template[o] > 0 and pattern[i] > 0:\n",
    "    #        score += pattern[ i ] * template[ o ]\n",
    "    #    #except:\n",
    "    #        #print( \"Error line 26\", pattern, template )\n",
    "\n",
    "    #return score\n",
    "\n",
    "\n",
    "\n",
    "def zero_padding( pattern, template ):\n",
    "    \"\"\"\n",
    "    Pad 1D template at begining and end of array with pattern length\n",
    " \n",
    "    Inputs:\n",
    "    ----------------\n",
    "        pattern   Pattern must be non empty and sum-square of its elements precalculated and passed\n",
    "\n",
    "        template   Template with similar dimensionality to pattern\n",
    "        \n",
    "    Output:\n",
    "    ----------------\n",
    "        template_padded  Padded template array \n",
    "     \"\"\"   \n",
    "    pattern = np.array(pattern)\n",
    "    template = np.array(template)\n",
    "\n",
    "    return np.pad(pattern, template)\n",
    "\n",
    "    ##Calculate pad size \n",
    "    #pad = [ 0 ] * ( len( pattern ) - 1 )\n",
    "    ##Pad begining and end of temple -1 for first element\n",
    "    #template_padded = pad + list(template) + pad\n",
    "\n",
    "    #return template_padded\n",
    "\n",
    "\n",
    "#function that finds the largest element and its index in an array\n",
    "def find_max( score ):\n",
    "    \"\"\"\n",
    "    Find max value in 1D array and its index\n",
    " \n",
    "    Inputs:\n",
    "    ----------------\n",
    "        score   1D target array\n",
    "        \n",
    "    Output:\n",
    "    ----------------\n",
    "        max_element Max Element in the array\n",
    "\n",
    "        index   Index of largest element \n",
    "\n",
    "     \"\"\"  \n",
    "    s = np.array( score )\n",
    "    max_element = np.amax( s )\n",
    "    index = np.argmax( s )\n",
    "\n",
    "    return max_element, index\n",
    "\n",
    "\n",
    "def norm_cross_corr( pattern, template, debug = False ): #change later to signal 1 and 2 as inputs\n",
    "    \"\"\"\n",
    "    Normed cross correlation of two 1D arrays\n",
    " \n",
    "    Inputs:\n",
    "    ----------------\n",
    "        pattern   Pattern must be non empty \n",
    "\n",
    "        template   Template, search space with similar dimensionality to pattern\n",
    "        \n",
    "    Output:\n",
    "    ----------------\n",
    "        norm_scores  Normed cross correlation array\n",
    "     \"\"\"       \n",
    "    pattern = np.array(pattern)\n",
    "    template = np.array(template)\n",
    "\n",
    "    return np.correlate(pattern, template)\n",
    "\n",
    "\n",
    "    len_p = len(pattern)\n",
    "    \n",
    "    #Pad and initalise arrays for calculation   \n",
    "    template_padded = zero_padding( pattern, template )\n",
    "    corr_len = len( template_padded ) - len_p\n",
    "    scores = [0.0] * ( corr_len ) #must cast as float for later calculations, prevent error (numba requires all floats)\n",
    "    norm = [0.0] * ( corr_len ) \n",
    "    norm_scores = [0.0] * ( corr_len ) \n",
    "    #test = [0] * ( len( template ) - len( pattern ) )\n",
    "    #t_start = time.time()\n",
    "    \n",
    "    #Precalculate pattern squared-sum and store, reduces calculation time by half \n",
    "    pattern_arr = np.array( pattern )\n",
    "    pattern_sq_sum = ( pattern_arr**2 ).sum() #to use in norm - memoised values to reduce number of computations\n",
    "    template_pad_arr = np.array( template_padded )\n",
    "    \n",
    "    #Find normed cross correlation from convolution of pattern with template array slices\n",
    "    t_start = time.time()\n",
    "    for i in range( len( scores ) ):\n",
    "        g_slice = template_pad_arr[ i : i + len_p ] \n",
    "        t_step = time.time()\n",
    "        #print( scores )\n",
    "        # print( pattern)\n",
    "        # print( template)\n",
    "        score_i = calculate_score( pattern, template_padded, i)\n",
    "        #print(score_i)\n",
    "        scores[ i ] = score_i\n",
    "        #scores[ i ] = calculate_score( pattern, template_padded, i)\n",
    "                #Whenever the norm is zero, the cross correlation is not calculated \n",
    "        if  scores[i]!=0 : \n",
    "            norm[ i ] = calculate_energy( pattern_sq_sum, g_slice)\n",
    "            norm_scores[i] = scores[ i ]/norm[ i ]\n",
    "        tn = time.time()\n",
    "        if debug: print( f'{ i } step time =  { tn - t_step} run time =  { tn - t_start}')\n",
    "        \n",
    "        #print( \"s=\", scores,\"\\n\", \"n=\", norm, \"\\n\")\n",
    "\n",
    "    return norm_scores\n",
    "\n",
    "\n",
    "def find_offset( corr, pattern ): \n",
    "    \"\"\"\n",
    "    1D array offset index and value from  cross correlation \n",
    " \n",
    "    Inputs:\n",
    "    ----------------\n",
    "        correlation_arr   Calculated array of cross correlation coefficients \n",
    "        \n",
    "    Output:\n",
    "    ----------------\n",
    "        (best_score, best_match)  Index of offset found from cross correlation\n",
    "     \"\"\"     \n",
    "\n",
    "    maxval, idx = find_max(corr) #clean this up\n",
    "    #print( best_match )\n",
    "\n",
    "    # subtract padding: - (len - 1)\n",
    "    return idx - len( pattern ) + 1, maxval \n",
    "\n",
    "\n",
    "# FYI: https://www.pythonforbeginners.com/files/with-statement-in-python\n",
    "def read_file( fileName ):\n",
    "    \"\"\"\n",
    "    Read input data file and filters for numerical values \n",
    " \n",
    "    Inputs:\n",
    "    ----------------\n",
    "        fileName   File path \n",
    " \n",
    "    Output:\n",
    "    ----------------\n",
    "        data_list  List of read of only numerical data values\n",
    "    \n",
    "    References:\n",
    "        super9super9 bronze badges, et al. \n",
    "        “Read File from Line 2 or Skip Header Row.” \n",
    "        Stack Overflow, 1 May 1960, stackoverflow.com/questions/4796764/read-file-from-line-2-or-skip-header-row.    \n",
    "    \"\"\"  \n",
    "    \n",
    "    data = open( fileName ,\"r\") \n",
    "    data_list = [float(line.strip() ) for line in islice(data, 1, None)] \n",
    "    data.close()\n",
    "         \n",
    "    return data_list\n",
    "\n",
    "\n",
    "\n",
    "#calculate signal offset for files in the local directory that are read into program\n",
    "\n",
    "def main():\n",
    "\n",
    "    debug = False\n",
    "    use_SSD = True #Calculate using library functions and mean\n",
    "    \n",
    "    #Read signal data\n",
    "    S1Data = read_file( \"sensor1Data.txt\" ) \n",
    "    S2Data = read_file( \"sensor2Data.txt\" )\n",
    "\n",
    "    # print( len(S1_Data), len( S2_Data ) )\n",
    "\n",
    "    #Debugging size for smaller runs \n",
    "    if debug:\n",
    "        Count=10000\n",
    "        t = []\n",
    "        S1_Data=[]\n",
    "        S2_Data=[]\n",
    "        for c in range(0,Count):\n",
    "            t.append(c+1) #Keep track of index position in loop\n",
    "            S1_Data.append(float(S1Data[c]))\n",
    "            S2_Data.append(float(S2Data[c]))\n",
    "    else:\n",
    "        S1_Data=S1Data\n",
    "        S2_Data=S2Data\n",
    "\n",
    "\n",
    "    print(\"Sensor-1 Data length = %d\"%len(S1_Data))\n",
    "    print(\"Sensor-2 Data length = %d\"%len(S2_Data))\n",
    "\n",
    "\n",
    "    #This method uses the mean and standard deviation to remove noise from the signal data\n",
    "    if use_SSD: \n",
    "        time_start = time.time()\n",
    "\n",
    "        S1_Mean = CalcMean( S1_Data )\n",
    "        S2_Mean = CalcMean( S2_Data )\n",
    "\n",
    "        S1_sdev = CalcSD( S1_Data )\n",
    "        S2_sdev = CalcSD( S2_Data ) \n",
    "\n",
    "        CCR = CalcCrossCorr( S1_Data, S2_Data)\n",
    "        NormCCR = CalcNormalisedCrossCorr( S1_Data, S2_Data, S1_Mean, S2_Mean, S1_sdev, S2_sdev)\n",
    "\n",
    "        #Use library functions to find CCR\n",
    "        npts = len( S1_Data )\n",
    "        t = np.linspace(0, len(S1_Data ), npts)\n",
    "        y1 = np.array( S1_Data )\n",
    "        y2 = np.array( S2_Data )        \n",
    "        ccov = np.correlate(y1 - y1.mean(), y2 - y2.mean(), mode='full')\n",
    "        n_ccor = ccov / (npts * y1.std() * y2.std())\n",
    "\n",
    "        t_total = time.time() - time_start\n",
    "        #Calculate domain of lagged times\n",
    "        lags = np.arange(-npts + 1, npts)\n",
    "\n",
    "        print(\"\\nMean of Sensor Data-1 = %f\"%S1_Mean)\n",
    "        print(\"Mean of Sensor Data-2 = %f\"%S2_Mean)\n",
    "\n",
    "        print(\"\\nStandard Deviation of Sensor Data-1  = %.3f\"%S1_sdev)\n",
    "        print(\"Standard Deviation of Sensor Data-2  = %.3f\"%S2_sdev)\n",
    "\n",
    "        print(\"\\nCross Correlation = %.3f\"%CCR)\n",
    "        print(\"Normalized Cross Correlation = %.3f\"%NormCCR)\n",
    "\n",
    "\n",
    "    #Do without SSD\n",
    "    else:\n",
    "        time_start = time.time()\n",
    "        # size = len(S1_Data)\n",
    "        n_ccor = norm_cross_corr( S1_Data, S2_Data, debug )\n",
    "        \n",
    "        offset, NormCCR = find_offset( n_ccor, S1Data )\n",
    "        \n",
    "        t_total = time.time() - time_start\n",
    "        #Calculate domain of lagged times\n",
    "        npts = len(S1_Data) - 1\n",
    "        lags = np.arange(-npts , npts)\n",
    "\n",
    "\n",
    "    #Plots of results\n",
    "    SubPlotRow=2\n",
    "    SubPlotCol=2\n",
    "\n",
    "    plt.subplot(SubPlotRow,SubPlotCol,1)\n",
    "    plt.plot(t,S1_Data, color = 'red')\n",
    "    plt.title(\"Sensor-1 Data Plot\")\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(SubPlotRow,SubPlotCol,2)\n",
    "    plt.plot(t,S2_Data, color = 'blue')\n",
    "    plt.title(\"Sensor-2 Data Plot\")\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(SubPlotRow,SubPlotCol,3)\n",
    "    plt.plot(t,S1_Data, color = 'red')\n",
    "    plt.plot(t,S2_Data, color = 'blue')\n",
    "    plt.title(\"Sensor-1 and Sensor-2 Combined Data Plot\")\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(SubPlotRow,SubPlotCol,4)\n",
    "    plt.plot(lags, n_ccor)\n",
    "    plt.ylim(-1.1, 1.1)\n",
    "    plt.ylabel('cross-correlation')\n",
    "    plt.xlabel('lag of Sensor-1 relative to Sensor-2')\n",
    "    plt.grid()\n",
    "\n",
    "    maxlag = lags[np.argmax(n_ccor)]\n",
    "    print(\"\\nmax correlation is at lag %d\" % maxlag)\n",
    "\n",
    "\n",
    "    #Calculation distance and plot of lag \n",
    "    offset = maxlag\n",
    "    Freq = 44000\n",
    "    sample_period = 1 / 44100\n",
    "    speed_sound = 333 \n",
    "\n",
    "    offset_time = offset * sample_period\n",
    "    sensor_distance = abs(offset * sample_period * speed_sound)\n",
    "\n",
    "    print(\"\\nFreq. = %d\"%Freq)\n",
    "    print(\"Off-Set = %d\"%offset)\n",
    "    print(\"Off-Set Time = %.3f\"%offset_time)\n",
    "    print(\"\\nDistance between two sensors = %.2f meters\"%sensor_distance)              \n",
    "    print( \"\\nRun time = %.2f\"%t_total )\n",
    "\n",
    "    plt.show()\n",
    " \n",
    "   \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
