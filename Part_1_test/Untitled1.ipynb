{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import islice\n",
    "from numba import jit\n",
    "\n",
    "#cache dictionary\n",
    "product_cache = {}\n",
    "\n",
    "\n",
    "def calculate_energy( p, g_slice ): # - memoise \n",
    "    \"\"\"\n",
    "    Normalisation for 1D slice of N size array of same length of pattern passed.\n",
    "    norm= sqrt( sum(p[i]^2) * sum(g[m]^2) )\n",
    " \n",
    "    Inputs:\n",
    "    ----------------\n",
    "        p   Pattern must be non empty and sum-square of its elements precalculated and passed\n",
    "\n",
    "        t   Template with similar dimensionality to pattern\n",
    "\n",
    "        offset  Offset position in the template/search array\n",
    "\n",
    "        len_p   offset for end-of-slice index for the slice of template\n",
    "        \n",
    "    Output:\n",
    "    ----------------\n",
    "        norm  Scalar float of variance for a given slice of the template/search and pattern\n",
    "     \"\"\"\n",
    "\n",
    "    return np.sqrt( np.sum( np.square*( p ) ) * np.sum( np.square( g ) ) )\n",
    "\n",
    "    #g_slice = t[ offset : offset + len_p ] \n",
    "    # norm = np.sqrt( p * ( g_slice**2).sum() ) \n",
    "    # if norm == 0 :\n",
    "    #     print (\"p=\", p, \"template=\", g_slice, \"offset = \", offset, \"\\n\")\n",
    "    # return norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Documents/GitHub/AOSC-Computervision/Part 1 test/sensor1Data.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-14ecdec06a6c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    299\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 300\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-14ecdec06a6c>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[1;31m#Read signal data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m     \u001b[0mS1Data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mread_file\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;34m\"Documents/GitHub/AOSC-Computervision/Part 1 test/sensor1Data.txt\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m     \u001b[0mS2Data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mread_file\u001b[0m\u001b[1;33m(\u001b[0m \u001b[1;34m\"Documents/GitHub/AOSC-Computervision/Part 1 test/sensor2Data.txt\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-14ecdec06a6c>\u001b[0m in \u001b[0;36mread_file\u001b[1;34m(fileName)\u001b[0m\n\u001b[0;32m    194\u001b[0m     \"\"\"  \n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mfileName\u001b[0m \u001b[1;33m,\u001b[0m\u001b[1;34m\"r\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m     \u001b[0mdata_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mislice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Documents/GitHub/AOSC-Computervision/Part 1 test/sensor1Data.txt'"
     ]
    }
   ],
   "source": [
    "\n",
    "#@jit(nopython=True)\n",
    "def calculate_score( pattern, template, offset):\n",
    "    \"\"\"\n",
    "    Correlation for 1D slice of N size template/search array with pattern at given offset. Sum(f[i]*g[i+m])\n",
    " \n",
    "    Inputs:\n",
    "    ----------------\n",
    "        pattern   Pattern must be non empty and sum-square of its elements precalculated and passed\n",
    "\n",
    "        template   Template with similar dimensionality to pattern\n",
    "\n",
    "        offset  Offset position in the template/search array\n",
    "        \n",
    "    Output:\n",
    "    ----------------\n",
    "        score  Scalar float of correlation score between pattern and template slice\n",
    "     \"\"\"    \n",
    "    #not faster \n",
    "    # slice_template = template[ offset : offset + len(pattern) ]\n",
    "    # score  = np.dot( pattern, slice_template ) \n",
    "    #Mutltiply and add each element of the pattern and template\n",
    "\n",
    "    pattern = np.array(pattern)\n",
    "    template = np.array(template)\n",
    "    \n",
    "    p = pattern.shape[0]\n",
    "    t = pattern.shape[0]\n",
    "\n",
    "    t_slice = template[offset : np.min(t, offset + p)]\n",
    "    p_slice = pattern[:t_slice.shape[0]]\n",
    "\n",
    "    return np.dot(t_slice, p_slice)\n",
    "\n",
    "    #score = 0 \n",
    "    #for i in range(len( pattern )):\n",
    "    #    o = i + offset\n",
    "    #    #try:\n",
    "    #    if template[o] > 0 and pattern[i] > 0:\n",
    "    #        score += pattern[ i ] * template[ o ]\n",
    "    #    #except:\n",
    "    #        #print( \"Error line 26\", pattern, template )\n",
    "\n",
    "    #return score\n",
    "\n",
    "\n",
    "\n",
    "def zero_padding( pattern, template ):\n",
    "    \"\"\"\n",
    "    Pad 1D template at begining and end of array with pattern length\n",
    " \n",
    "    Inputs:\n",
    "    ----------------\n",
    "        pattern   Pattern must be non empty and sum-square of its elements precalculated and passed\n",
    "\n",
    "        template   Template with similar dimensionality to pattern\n",
    "        \n",
    "    Output:\n",
    "    ----------------\n",
    "        template_padded  Padded template array \n",
    "     \"\"\"   \n",
    "    pattern = np.array(pattern)\n",
    "    template = np.array(template)\n",
    "\n",
    "    return np.pad(pattern, template)\n",
    "\n",
    "    ##Calculate pad size \n",
    "    #pad = [ 0 ] * ( len( pattern ) - 1 )\n",
    "    ##Pad begining and end of temple -1 for first element\n",
    "    #template_padded = pad + list(template) + pad\n",
    "\n",
    "    #return template_padded\n",
    "\n",
    "\n",
    "#function that finds the largest element and its index in an array\n",
    "def find_max( score ):\n",
    "    \"\"\"\n",
    "    Find max value in 1D array and its index\n",
    " \n",
    "    Inputs:\n",
    "    ----------------\n",
    "        score   1D target array\n",
    "        \n",
    "    Output:\n",
    "    ----------------\n",
    "        max_element Max Element in the array\n",
    "\n",
    "        index   Index of largest element \n",
    "\n",
    "     \"\"\"  \n",
    "    s = np.array( score )\n",
    "    max_element = np.amax( s )\n",
    "    index = np.argmax( s )\n",
    "\n",
    "    return max_element, index\n",
    "\n",
    "\n",
    "def norm_cross_corr( pattern, template, debug = False ): #change later to signal 1 and 2 as inputs\n",
    "    \"\"\"\n",
    "    Normed cross correlation of two 1D arrays\n",
    " \n",
    "    Inputs:\n",
    "    ----------------\n",
    "        pattern   Pattern must be non empty \n",
    "\n",
    "        template   Template, search space with similar dimensionality to pattern\n",
    "        \n",
    "    Output:\n",
    "    ----------------\n",
    "        norm_scores  Normed cross correlation array\n",
    "     \"\"\"       \n",
    "    pattern = np.array(pattern)\n",
    "    template = np.array(template)\n",
    "\n",
    "    return np.correlate(pattern, template)\n",
    "\n",
    "\n",
    "    len_p = len(pattern)\n",
    "    \n",
    "    #Pad and initalise arrays for calculation   \n",
    "    template_padded = zero_padding( pattern, template )\n",
    "    corr_len = len( template_padded ) - len_p\n",
    "    scores = [0.0] * ( corr_len ) #must cast as float for later calculations, prevent error (numba requires all floats)\n",
    "    norm = [0.0] * ( corr_len ) \n",
    "    norm_scores = [0.0] * ( corr_len ) \n",
    "    #test = [0] * ( len( template ) - len( pattern ) )\n",
    "    #t_start = time.time()\n",
    "    \n",
    "    #Precalculate pattern squared-sum and store, reduces calculation time by half \n",
    "    pattern_arr = np.array( pattern )\n",
    "    pattern_sq_sum = ( pattern_arr**2 ).sum() #to use in norm - memoised values to reduce number of computations\n",
    "    template_pad_arr = np.array( template_padded )\n",
    "    \n",
    "    #Find normed cross correlation from convolution of pattern with template array slices\n",
    "    t_start = time.time()\n",
    "    for i in range( len( scores ) ):\n",
    "        g_slice = template_pad_arr[ i : i + len_p ] \n",
    "        t_step = time.time()\n",
    "        #print( scores )\n",
    "        # print( pattern)\n",
    "        # print( template)\n",
    "        score_i = calculate_score( pattern, template_padded, i)\n",
    "        #print(score_i)\n",
    "        scores[ i ] = score_i\n",
    "        #scores[ i ] = calculate_score( pattern, template_padded, i)\n",
    "                #Whenever the norm is zero, the cross correlation is not calculated \n",
    "        if  scores[i]!=0 : \n",
    "            norm[ i ] = calculate_energy( pattern_sq_sum, g_slice)\n",
    "            norm_scores[i] = scores[ i ]/norm[ i ]\n",
    "        tn = time.time()\n",
    "        if debug: print( f'{ i } step time =  { tn - t_step} run time =  { tn - t_start}')\n",
    "        \n",
    "        #print( \"s=\", scores,\"\\n\", \"n=\", norm, \"\\n\")\n",
    "\n",
    "    return norm_scores\n",
    "\n",
    "\n",
    "def find_offset( corr, pattern ): \n",
    "    \"\"\"\n",
    "    1D array offset index and value from  cross correlation \n",
    " \n",
    "    Inputs:\n",
    "    ----------------\n",
    "        correlation_arr   Calculated array of cross correlation coefficients \n",
    "        \n",
    "    Output:\n",
    "    ----------------\n",
    "        (best_score, best_match)  Index of offset found from cross correlation\n",
    "     \"\"\"     \n",
    "\n",
    "    maxval, idx = find_max(corr) #clean this up\n",
    "    #print( best_match )\n",
    "\n",
    "    # subtract padding: - (len - 1)\n",
    "    return idx - len( pattern ) + 1, maxval \n",
    "\n",
    "\n",
    "# FYI: https://www.pythonforbeginners.com/files/with-statement-in-python\n",
    "def read_file( fileName ):\n",
    "    \"\"\"\n",
    "    Read input data file and filters for numerical values \n",
    " \n",
    "    Inputs:\n",
    "    ----------------\n",
    "        fileName   File path \n",
    " \n",
    "    Output:\n",
    "    ----------------\n",
    "        data_list  List of read of only numerical data values\n",
    "    \n",
    "    References:\n",
    "        super9super9 bronze badges, et al. \n",
    "        “Read File from Line 2 or Skip Header Row.” \n",
    "        Stack Overflow, 1 May 1960, stackoverflow.com/questions/4796764/read-file-from-line-2-or-skip-header-row.    \n",
    "    \"\"\"  \n",
    "    \n",
    "    data = open( fileName ,\"r\") \n",
    "    data_list = [float(line.strip() ) for line in islice(data, 1, None)] \n",
    "    data.close()\n",
    "         \n",
    "    return data_list\n",
    "\n",
    "\n",
    "\n",
    "#calculate signal offset for files in the local directory that are read into program\n",
    "\n",
    "def main():\n",
    "\n",
    "    debug = False\n",
    "    use_SSD = True #Calculate using library functions and mean\n",
    "    \n",
    "    #Read signal data\n",
    "    S1Data = np.array(read_file( \"Documents/GitHub/AOSC-Computervision/Part 1 test/sensor1Data.txt\") )\n",
    "    S2Data = np.array(read_file( \"Documents/GitHub/AOSC-Computervision/Part 1 test/sensor2Data.txt\") )\n",
    "                      \n",
    "    # print( len(S1_Data), len( S2_Data ) )\n",
    "\n",
    "    #Debugging size for smaller runs \n",
    "    if debug:\n",
    "        Count=10000\n",
    "        t = []\n",
    "        S1_Data=[]\n",
    "        S2_Data=[]\n",
    "        for c in range(0,Count):\n",
    "            t.append(c+1) #Keep track of index position in loop\n",
    "            S1_Data.append(float(S1Data[c]))\n",
    "            S2_Data.append(float(S2Data[c]))\n",
    "    else:\n",
    "        S1_Data=S1Data\n",
    "        S2_Data=S2Data\n",
    "\n",
    "\n",
    "    print(\"Sensor-1 Data length = %d\"%len(S1_Data))\n",
    "    print(\"Sensor-2 Data length = %d\"%len(S2_Data))\n",
    "\n",
    "\n",
    "    time_start = time.time()\n",
    "    # size = len(S1_Data)\n",
    "    n_ccor = norm_cross_corr( S1_Data, S2_Data, debug )\n",
    "\n",
    "    offset, NormCCR = find_offset( n_ccor, S1Data )\n",
    "\n",
    "    t_total = time.time() - time_start\n",
    "    #Calculate domain of lagged times\n",
    "    npts = len(S1_Data) - 1\n",
    "    lags = np.arange(-npts , npts)\n",
    "\n",
    "\n",
    "    #Plots of results\n",
    "    SubPlotRow=2\n",
    "    SubPlotCol=2\n",
    "\n",
    "    plt.subplot(SubPlotRow,SubPlotCol,1)\n",
    "    plt.plot(t,S1_Data, color = 'red')\n",
    "    plt.title(\"Sensor-1 Data Plot\")\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(SubPlotRow,SubPlotCol,2)\n",
    "    plt.plot(t,S2_Data, color = 'blue')\n",
    "    plt.title(\"Sensor-2 Data Plot\")\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(SubPlotRow,SubPlotCol,3)\n",
    "    plt.plot(t,S1_Data, color = 'red')\n",
    "    plt.plot(t,S2_Data, color = 'blue')\n",
    "    plt.title(\"Sensor-1 and Sensor-2 Combined Data Plot\")\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(SubPlotRow,SubPlotCol,4)\n",
    "    plt.plot(lags, n_ccor)\n",
    "    plt.ylim(-1.1, 1.1)\n",
    "    plt.ylabel('cross-correlation')\n",
    "    plt.xlabel('lag of Sensor-1 relative to Sensor-2')\n",
    "    plt.grid()\n",
    "\n",
    "    maxlag = lags[np.argmax(n_ccor)]\n",
    "    print(\"\\nmax correlation is at lag %d\" % maxlag)\n",
    "\n",
    "\n",
    "    #Calculation distance and plot of lag \n",
    "    offset = maxlag\n",
    "    Freq = 44000\n",
    "    sample_period = 1 / 44100\n",
    "    speed_sound = 333 \n",
    "\n",
    "    offset_time = offset * sample_period\n",
    "    sensor_distance = abs(offset * sample_period * speed_sound)\n",
    "\n",
    "    print(\"\\nFreq. = %d\"%Freq)\n",
    "    print(\"Off-Set = %d\"%offset)\n",
    "    print(\"Off-Set Time = %.3f\"%offset_time)\n",
    "    print(\"\\nDistance between two sensors = %.2f meters\"%sensor_distance)              \n",
    "    print( \"\\nRun time = %.2f\"%t_total )\n",
    "\n",
    "    plt.show()\n",
    " \n",
    "   \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
