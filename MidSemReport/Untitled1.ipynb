{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensor-1 Data length = 176401\n",
      "Sensor-2 Data length = 176401\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-96046c1d02cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    379\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 381\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    382\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-96046c1d02cd>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    309\u001b[0m         \u001b[0mtime_start\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mS1_Data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m         \u001b[0mn_ccor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnorm_cross_corr\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mS1_Data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mS2_Data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdebug\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[0moffset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNormCCR\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_offset\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mn_ccor\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-96046c1d02cd>\u001b[0m in \u001b[0;36mnorm_cross_corr\u001b[1;34m(pattern, template, debug)\u001b[0m\n\u001b[0;32m    182\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;33m)\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[0mt_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m         \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcalculate_score\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtemplate_padded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m         \u001b[1;31m#print( scores )\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m         \u001b[1;31m#Whenever the norm is zero, the cross correlation is not calculated\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-96046c1d02cd>\u001b[0m in \u001b[0;36mcalculate_score\u001b[1;34m(pattern, template, offset)\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0mo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;31m#try:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m             \u001b[0mscore\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m[\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[1;33m[\u001b[0m \u001b[0mo\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;31m#except:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import islice\n",
    "\n",
    "#cache dictionary\n",
    "product_cache = {}\n",
    "\n",
    "#version 2\n",
    "#Added functions to improve computation time \n",
    "#1\n",
    "def CalcMean(lst):\n",
    "    Sum = 0\n",
    "    for i in range(0,len(lst)):\n",
    "        Sum = Sum + lst[i]\n",
    "    Mean = Sum/len(lst)    \n",
    "    return(Mean)\n",
    "\n",
    "#2\n",
    "def CalcSD(lst,Mean):\n",
    "    SD = 0\n",
    "    for i in range(0,len(lst)):\n",
    "        SD = SD + (lst[i]-Mean)*(lst[i]-Mean)\n",
    "    SD = math.sqrt(SD/len(lst))        \n",
    "    return(SD)    \n",
    "\n",
    "#3\n",
    "def CalcCrossCorr(f,g,fmean,gmean):\n",
    "    Sum=0\n",
    "    for i in range(0,len(f)):\n",
    "        Sum = Sum + (f[i]-fmean)*(g[i]-gmean)\n",
    "    CrossCorr = Sum/len(f)\n",
    "    return(CrossCorr)\n",
    "\n",
    "#4    \n",
    "def CalcNormalisedCrossCorr(f,g,fmean,gmean,fsd,gsd):\n",
    "    Sum = 0\n",
    "    for i in range(0,len(f)):\n",
    "        Sum = Sum + (f[i]-fmean)*(g[i]-gmean)\n",
    "    NormCrossCorr = Sum/(len(f)*fsd*gsd)\n",
    "    return(NormCrossCorr)\n",
    "\n",
    "\n",
    "def calculate_energy( p, t, offset, len_p ): # - memoise \n",
    "    \"\"\"\n",
    "    Normalisation for 1D slice of N size array of same length of pattern passed.\n",
    "    norm= sqrt( sum(f[i]^2) * sum(g[m]^2) )\n",
    " \n",
    "    Inputs:\n",
    "    ----------------\n",
    "        p   Pattern must be non empty and sum-square of its elements precalculated and passed\n",
    "\n",
    "        t   Template with similar dimensionality to pattern\n",
    "\n",
    "        offset  Offset position in the template/search array\n",
    "\n",
    "        len_p   offset for end-of-slice index for the slice of template\n",
    "        \n",
    "    Output:\n",
    "    ----------------\n",
    "        norm  Scalar float of variance for a given slice of the template/search and pattern\n",
    "     \"\"\"\n",
    "    g_slice = t[ offset : offset + len_p ] \n",
    "    norm = np.sqrt( p * ( g_slice**2).sum() ) \n",
    "    # if norm == 0 :\n",
    "    #     print (\"p=\", p, \"template=\", g_slice, \"offset = \", offset, \"\\n\")\n",
    "    return norm\n",
    "\n",
    "\n",
    "def calculate_score( pattern, template, offset):\n",
    "    \"\"\"\n",
    "    Correlation for 1D slice of N size template/search array with pattern at given offset. Sum(f[i]*g[i+m])\n",
    " \n",
    "    Inputs:\n",
    "    ----------------\n",
    "        pattern   Pattern must be non empty and sum-square of its elements precalculated and passed\n",
    "\n",
    "        template   Template with similar dimensionality to pattern\n",
    "\n",
    "        offset  Offset position in the template/search array\n",
    "        \n",
    "    Output:\n",
    "    ----------------\n",
    "        score  Scalar float of correlation score between pattern and template slice\n",
    "     \"\"\"    \n",
    "    #not faster \n",
    "    # slice_template = template[ offset : offset + len(pattern) ]\n",
    "    # score  = np.dot( pattern, slice_template ) \n",
    "    #Mutltiply and add each element of the pattern and template\n",
    "    score = 0 \n",
    "    for i in range(len( pattern )):\n",
    "        o = i + offset\n",
    "        #try:\n",
    "        if template[o] > 0 and pattern[i] > 0:\n",
    "            score += pattern[ i ] * template[ o ]\n",
    "        #except:\n",
    "            #print( \"Error line 26\", pattern, template )\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "\n",
    "def zero_padding( pattern, template ):\n",
    "    \"\"\"\n",
    "    Pad 1D template at begining and end of array with pattern length\n",
    " \n",
    "    Inputs:\n",
    "    ----------------\n",
    "        pattern   Pattern must be non empty and sum-square of its elements precalculated and passed\n",
    "\n",
    "        template   Template with similar dimensionality to pattern\n",
    "        \n",
    "    Output:\n",
    "    ----------------\n",
    "        template_padded  Padded template array \n",
    "     \"\"\"    \n",
    "    #Calculate pad size \n",
    "    pad = [ 0 ] * ( len( pattern ) - 1 )\n",
    "    #Pad begining and end of temple -1 for first element\n",
    "    template_padded = pad + list(template) + pad\n",
    "\n",
    "    return template_padded\n",
    "\n",
    "\n",
    "#function that finds the largest element and its index in an array\n",
    "def find_best_match( score ):\n",
    "    \"\"\"\n",
    "    Find max value in 1D array and its index\n",
    " \n",
    "    Inputs:\n",
    "    ----------------\n",
    "        score   1D target array\n",
    "        \n",
    "    Output:\n",
    "    ----------------\n",
    "        max_element Max Element in the array\n",
    "\n",
    "        index   Index of largest element \n",
    "\n",
    "     \"\"\"       \n",
    "    s = np.array( score )\n",
    "    try:\n",
    "        max_element = np.amax( s )\n",
    "    except:\n",
    "        print( \"Line 45 Error\", score )\n",
    "    index = np.argmax( s )\n",
    "\n",
    "    return max_element, index\n",
    "\n",
    "\n",
    "def norm_cross_corr( pattern, template, debug = False ): #change later to signal 1 and 2 as inputs\n",
    "    \"\"\"\n",
    "    Normed cross correlation of two 1D arrays\n",
    " \n",
    "    Inputs:\n",
    "    ----------------\n",
    "        pattern   Pattern must be non empty \n",
    "\n",
    "        template   Template, search space with similar dimensionality to pattern\n",
    "        \n",
    "    Output:\n",
    "    ----------------\n",
    "        norm_scores  Normed cross correlation array\n",
    "     \"\"\"       \n",
    "\n",
    "    #Pad and initalise arrays for calculation   \n",
    "    template_padded = zero_padding( pattern, template )\n",
    "    corr_len = len( template_padded ) - len( pattern )\n",
    "    scores = [0] * ( corr_len )\n",
    "    norm = [0] * ( corr_len ) \n",
    "    norm_scores = [0] * ( corr_len ) \n",
    "    #test = [0] * ( len( template ) - len( pattern ) )\n",
    "    #t_start = time.time()\n",
    "    \n",
    "    #Precalculate pattern squared-sum and store, reduces calculation time by half \n",
    "    pattern_arr = np.array( pattern )\n",
    "    pattern_sq_sum = ( pattern_arr**2 ).sum() #to use in norm - memoised values to reduce number of computations\n",
    "    template_pad_arr = np.array( template_padded )\n",
    "    \n",
    "    #Find normed cross correlation from convolution of pattern with template array slices\n",
    "    t_start = time.time()\n",
    "    for i in range( len( scores ) ):\n",
    "        t_step = time.time()\n",
    "        scores[ i ] = calculate_score( pattern, template_padded, i)\n",
    "        #print( scores )\n",
    "        #Whenever the norm is zero, the cross correlation is not calculated \n",
    "        if  scores[i]!=0 : \n",
    "            norm[ i ] = calculate_energy( pattern_sq_sum, template_pad_arr, i, len(pattern))\n",
    "            norm_scores[i] = scores[ i ]/norm[ i ]\n",
    "        tn = time.time()\n",
    "        if debug: print( f'{ i } step time =  { tn - t_step} run time =  { tn - t_start}')\n",
    "        \n",
    "        #print( \"s=\", scores,\"\\n\", \"n=\", norm, \"\\n\")\n",
    "\n",
    "    return norm_scores\n",
    "\n",
    "\n",
    "def find_offset( correlation_arr ): \n",
    "    \"\"\"\n",
    "    1D array offset index and value from  cross correlation \n",
    " \n",
    "    Inputs:\n",
    "    ----------------\n",
    "        correlation_arr   Calculated array of cross correlation coefficients \n",
    "        \n",
    "    Output:\n",
    "    ----------------\n",
    "        (best_score, best_match)  Index of offset found from cross correlation\n",
    "     \"\"\"     \n",
    "\n",
    "    best_score, best_match = find_best_match( correlation_arr )\n",
    "    #print( best_match )\n",
    "\n",
    "    # subtract padding: - (len - 1)\n",
    "    return best_match - len( pattern ) + 1, best_score \n",
    "\n",
    "\n",
    "\n",
    "def read_file( fileName ):\n",
    "    \"\"\"\n",
    "    Read input data file and filters for numerical values \n",
    " \n",
    "    Inputs:\n",
    "    ----------------\n",
    "        fileName   File path \n",
    " \n",
    "    Output:\n",
    "    ----------------\n",
    "        data_list  List of read of only numerical data values\n",
    "    \n",
    "    References:\n",
    "        super9super9 bronze badges, et al. \n",
    "        “Read File from Line 2 or Skip Header Row.” \n",
    "        Stack Overflow, 1 May 1960, stackoverflow.com/questions/4796764/read-file-from-line-2-or-skip-header-row.    \n",
    "    \"\"\"  \n",
    "    \n",
    "    data = open( fileName ,\"r\") \n",
    "    data_list = [float(line.strip() ) for line in islice(data, 1, None)] \n",
    "    data.close()\n",
    "         \n",
    "    return data_list\n",
    "\n",
    "\n",
    "\n",
    "#calculate signal offset for files in the local directory that are read into program\n",
    "\n",
    "def main():\n",
    "\n",
    "    debug = False\n",
    "    use_SSD = False #Calculate using library functions and mean\n",
    "    \n",
    "    #Read signal data\n",
    "    S1_Data = read_file( \"sensor1Data.txt\" ) \n",
    "    S2_Data = read_file( \"sensor2Data.txt\" )\n",
    "\n",
    "    # print( len(S1_Data), len( S2_Data ) )\n",
    "\n",
    "    #Debugging size for smaller runs \n",
    "    if debug:\n",
    "        Count=100000\n",
    "        t = []\n",
    "        for c in range(0,Count):\n",
    "            t.append(c+1) #Keep track of index position in loop\n",
    "            S1_Data.append(float(S1_Data[c]))\n",
    "            S2_Data.append(float(S2_Data[c]))\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "    print(\"Sensor-1 Data length = %d\"%len(S1_Data))\n",
    "    print(\"Sensor-2 Data length = %d\"%len(S2_Data))\n",
    "\n",
    "\n",
    "    #This method uses the mean and standard deviation to remove noise from the signal data\n",
    "    if use_SSD: \n",
    "        time_start = time.time()\n",
    "\n",
    "        S1_Mean = CalcMean( S1_Data )\n",
    "        S2_Mean = CalcMean( S2_Data )\n",
    "\n",
    "        S1_sdev = CalcSD( S1_Data, S1_Mean )\n",
    "        S2_sdev = CalcSD( S2_Data, S2_Mean ) \n",
    "\n",
    "        CCR = CalcCrossCorr( S1_Data, S2_Data,S1_Mean, S2_Mean)\n",
    "        NormCCR = CalcNormalisedCrossCorr( S1_Data, S2_Data, S1_Mean, S2_Mean, S1_sdev, S2_sdev)\n",
    "\n",
    "        #Use library functions to find CCR\n",
    "        npts = len( S1_Data )\n",
    "        t = np.linspace(0, len(S1_Data ), npts)\n",
    "        y1 = np.array( S1_Data )\n",
    "        y2 = np.array( S2_Data )        \n",
    "        ccov = np.correlate(y1 - y1.mean(), y2 - y2.mean(), mode='full')\n",
    "        n_ccor = ccov / (npts * y1.std() * y2.std())\n",
    "\n",
    "        t_total = time.time() - time_start\n",
    "\n",
    "        print(\"\\nMean of Sensor Data-1 = %f\"%S1_Mean)\n",
    "        print(\"Mean of Sensor Data-2 = %f\"%S2_Mean)\n",
    "\n",
    "        print(\"\\nStandard Deviation of Sensor Data-1  = %.3f\"%S1_sdev)\n",
    "        print(\"Standard Deviation of Sensor Data-2  = %.3f\"%S2_sdev)\n",
    "\n",
    "        print(\"\\nCross Correlation = %.3f\"%CCR)\n",
    "        print(\"Normalized Cross Correlation = %.3f\"%NormCCR)\n",
    "\n",
    "\n",
    "    #Do without SSD\n",
    "    else:\n",
    "        time_start = time.time()\n",
    "        size = len(S1_Data)\n",
    "        n_ccor = norm_cross_corr( S1_Data[:size], S2_Data[:size], debug )\n",
    "        \n",
    "        offset, NormCCR = find_offset( n_ccor )\n",
    "        \n",
    "        t_total = time.time() - time_start\n",
    "\n",
    "\n",
    "    #Plots of results\n",
    "    SubPlotRow=2\n",
    "    SubPlotCol=2\n",
    "\n",
    "    plt.subplot(SubPlotRow,SubPlotCol,1)\n",
    "    plt.plot(t,S1_Data, color = 'red')\n",
    "    plt.title(\"Sensor-1 Data Plot\")\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(SubPlotRow,SubPlotCol,2)\n",
    "    plt.plot(t,S2_Data, color = 'blue')\n",
    "    plt.title(\"Sensor-2 Data Plot\")\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(SubPlotRow,SubPlotCol,3)\n",
    "    plt.plot(t,S1_Data, color = 'red')\n",
    "    plt.plot(t,S2_Data, color = 'blue')\n",
    "    plt.title(\"Sensor-1 and Sensor-2 Combined Data Plot\")\n",
    "    plt.grid()\n",
    "\n",
    "    #Calculate domain of lagged times\n",
    "    npts = len(S1_Data)\n",
    "    lags = np.arange(-npts + 1, npts)\n",
    "\n",
    "    plt.subplot(SubPlotRow,SubPlotCol,4)\n",
    "    plt.plot(lags, n_ccor)\n",
    "    plt.ylim(-1.1, 1.1)\n",
    "    plt.ylabel('cross-correlation')\n",
    "    plt.xlabel('lag of Sensor-1 relative to Sensor-2')\n",
    "    plt.grid()\n",
    "\n",
    "    plt.subplot(SubPlotRow,SubPlotCol,4)\n",
    "    plt.plot(lags, n_ccor)\n",
    "    plt.ylim(-1.1, 1.1)\n",
    "    plt.ylabel('cross-correlation')\n",
    "    plt.xlabel('lag of Sensor-1 relative to Sensor-2')\n",
    "    plt.grid()\n",
    "\n",
    "    maxlag = lags[np.argmax(n_ccor)]\n",
    "    print(\"\\nmax correlation is at lag %d\" % maxlag)\n",
    "\n",
    "\n",
    "    #Calculation distance and plot of lag \n",
    "    offset = maxlag\n",
    "    Freq = 44000\n",
    "    sample_period = 1 / 44100\n",
    "    speed_sound = 333 \n",
    "\n",
    "    offset_time = offset * sample_period\n",
    "    sensor_distance = abs(offset * sample_period * speed_sound)\n",
    "\n",
    "    print(\"\\nFreq. = %d\"%Freq)\n",
    "    print(\"Off-Set = %d\"%offset)\n",
    "    print(\"Off-Set Time = %.3f\"%offset_time)\n",
    "    print(\"\\nDistance between two sensors = %.2f meters\"%sensor_distance)              \n",
    "    print( \"\\nRun time = %.2f\"%t_total )\n",
    "\n",
    "    plt.show()\n",
    " \n",
    "   \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    main()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
